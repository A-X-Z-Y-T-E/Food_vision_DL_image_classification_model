{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "j4z8yE-aAhvF"
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfUn1KQ-DnI2",
        "outputId": "e5581725-cacd-4c55-e28e-cd0fdfede344"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-535f7ae9-0c3a-d015-a687-7c1768e6cb44)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4_gRpPUENnu",
        "outputId": "b39cfc07-9f99-4d26-e9f2-8ebeab70cf10"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-27 13:35:32--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-06-27 13:35:33 (77.5 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import *"
      ],
      "metadata": {
        "id": "aWB_G3tGE3jr"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Specify a directory to save the dataset\n",
        "data_dir = '/content/Food_vision_data/'\n",
        "\n",
        "# Create a builder for the dataset\n",
        "builder = tfds.builder(\"food101\", data_dir=data_dir)\n",
        "\n",
        "# Download and prepare the dataset\n",
        "builder.download_and_prepare()\n",
        "\n",
        "# Load the dataset from the specified directory\n",
        "(train_data, test_data), ds_info = tfds.load(name=\"food101\",\n",
        "                                             split=[\"train\", \"validation\"],\n",
        "                                             shuffle_files=True,\n",
        "                                             with_info=True,\n",
        "                                             as_supervised=True,\n",
        "                                             data_dir=data_dir)\n"
      ],
      "metadata": {
        "id": "HZBOZcXn1Qjs"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ds_info.features[\"label\"].names\n"
      ],
      "metadata": {
        "id": "m6l-D6ndyv1q"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a function for preprocessing images\n",
        "def preprocess_img(image, label, img_shape=224):\n",
        "    \"\"\"\n",
        "    Converts image datatype from 'uint8' -> 'float32' and reshapes image to\n",
        "    [img_shape, img_shape, color_channels]\n",
        "    \"\"\"\n",
        "    image = tf.image.resize(image, [img_shape, img_shape]) # reshape to img_shape\n",
        "    return tf.cast(image, tf.float32), label # return (float32_image, label) tuple"
      ],
      "metadata": {
        "id": "qgWB_MFSOjcS"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Map preprocessing function to training data (and paralellize)\n",
        "train_data = train_data.map(map_func=preprocess_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "# Shuffle train_data and turn it into batches and prefetch it (load it faster)\n",
        "train_data = train_data.shuffle(buffer_size=1000).batch(batch_size=32).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "# Map prepreprocessing function to test data\n",
        "test_data = test_data.map(preprocess_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "# Turn test data into batches (don't need to shuffle)\n",
        "test_data = test_data.batch(32).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "eu3hyIdMPG19"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create ModelCheckpoint callback to save model's progress\n",
        "checkpoint_path = \"model_checkpoints/cp.ckpt\" # saving weights requires \".ckpt\" extension\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "                                                      monitor=\"val_accuracy\", # save the model weights with best validation accuracy\n",
        "                                                      save_best_only=True, # only save the best weights\n",
        "                                                      save_weights_only=True, # only save model weights (not whole model)\n",
        "                                                      verbose=0) # don't print out whether or not model is being saved"
      ],
      "metadata": {
        "id": "s41ohZhHvwsV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"model_checkpoint_B7/cp.ckpt\" # saving weights requires \".ckpt\" extension\n",
        "model_checkpoint_B7 = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "                                                      monitor=\"val_accuracy\", # save the model weights with best validation accuracy\n",
        "                                                      save_best_only=True, # only save the best weights\n",
        "                                                      save_weights_only=True, # only save model weights (not whole model)\n",
        "                                                      verbose=0) # don't print out whether or not model is being saved"
      ],
      "metadata": {
        "id": "_rO-s81pWudm"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Define the EarlyStopping callback\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',  # Metric to monitor\n",
        "    patience=3,          # Number of epochs with no improvement after which training will be stopped\n",
        "    verbose=1,           # Verbosity mode\n",
        "    restore_best_weights=True  # Whether to restore model weights from the epoch with the best value of the monitored quantity\n",
        ")"
      ],
      "metadata": {
        "id": "XgaTn9Dhy__0"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn on mixed precision training\n",
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy(policy=\"mixed_float16\") # set global policy to mixed precision"
      ],
      "metadata": {
        "id": "LmkySOwOzU2K"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "# Create base model\n",
        "input_shape = (224, 224, 3)\n",
        "base_model = tf.keras.applications.EfficientNetB7(include_top=False)\n",
        "base_model.trainable = False # freeze base model layers\n",
        "\n",
        "# Create Functional model\n",
        "inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n",
        "# Note: EfficientNetBX models have rescaling built-in but if your model didn't you could have a layer like below\n",
        "# x = layers.Rescaling(1./255)(x)\n",
        "x = base_model(inputs, training=False) # set base_model to inference mode only\n",
        "x = layers.GlobalAveragePooling2D(name=\"pooling_layer\")(x)\n",
        "x = layers.Dense(len(class_names))(x) # want one output neuron per class\n",
        "# Separate activation of output layer so we can output float32 activations\n",
        "outputs = layers.Activation(\"softmax\", dtype=tf.float32, name=\"softmax_float32\")(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", # Use sparse_categorical_crossentropy when labels are *not* one-hot\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "v1RwnZJo0EEz"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn off all warnings except for errors\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "# Fit the model with callbacks\n",
        "history_101_food_classes_feature_extract = model.fit(train_data,\n",
        "                                                     epochs=3,\n",
        "                                                     steps_per_epoch=len(train_data),\n",
        "                                                     validation_data=test_data,\n",
        "                                                     validation_steps=int(0.10 * len(test_data)),\n",
        "                                                     callbacks=[early_stopping,\n",
        "                                                                model_checkpoint])"
      ],
      "metadata": {
        "id": "boq7kuBX0MDt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f080814c-47f9-4fd0-a0ae-e3560e36ca7a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "2368/2368 [==============================] - 517s 208ms/step - loss: 1.7917 - accuracy: 0.5531 - val_loss: 1.2595 - val_accuracy: 0.6590\n",
            "Epoch 2/3\n",
            "2368/2368 [==============================] - 496s 209ms/step - loss: 1.3179 - accuracy: 0.6565 - val_loss: 1.1572 - val_accuracy: 0.6903\n",
            "Epoch 3/3\n",
            "2368/2368 [==============================] - 491s 206ms/step - loss: 1.1624 - accuracy: 0.6948 - val_loss: 1.1219 - val_accuracy: 0.6950\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extr_eval = model.evaluate(test_data)\n",
        "feature_extr_eval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_8W4mOrRJ6T",
        "outputId": "4ce074a7-4baf-495e-a413-df0b5eb828d4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "790/790 [==============================] - 150s 190ms/step - loss: 1.1348 - accuracy: 0.6962\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.1348329782485962, 0.696198046207428]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_dir = \"07_efficientnetb7_feature_extract_model_mixed_precision\"\n",
        "model.save(save_dir)"
      ],
      "metadata": {
        "id": "3WyPFti1Py4L"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/07_efficientnetb0_feature_extract_model_mixed_precision.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AanLaHgxP5OC",
        "outputId": "bdb6c731-3bb6-4727-cdb4-7c2540241c9f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-27 15:15:01--  https://storage.googleapis.com/ztm_tf_course/food_vision/07_efficientnetb0_feature_extract_model_mixed_precision.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.79.207, 108.177.96.207, 108.177.119.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.79.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16976857 (16M) [application/zip]\n",
            "Saving to: ‘07_efficientnetb0_feature_extract_model_mixed_precision.zip’\n",
            "\n",
            "07_efficientnetb0_f 100%[===================>]  16.19M  12.8MB/s    in 1.3s    \n",
            "\n",
            "2024-06-27 15:15:03 (12.8 MB/s) - ‘07_efficientnetb0_feature_extract_model_mixed_precision.zip’ saved [16976857/16976857]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # Unzip the SavedModel downloaded from Google Stroage\n",
        "!mkdir downloaded_gs_model # create new dir to store downloaded feature extraction model\n",
        "!unzip 07_efficientnetb0_feature_extract_model_mixed_precision.zip -d downloaded_gs_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHGQ8DELP9C1",
        "outputId": "461e57ce-3dd4-4c01-eb06-f90112fae2a8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  07_efficientnetb0_feature_extract_model_mixed_precision.zip\n",
            "   creating: downloaded_gs_model/07_efficientnetb0_feature_extract_model_mixed_precision/\n",
            "   creating: downloaded_gs_model/07_efficientnetb0_feature_extract_model_mixed_precision/variables/\n",
            "  inflating: downloaded_gs_model/07_efficientnetb0_feature_extract_model_mixed_precision/variables/variables.data-00000-of-00001  \n",
            "  inflating: downloaded_gs_model/07_efficientnetb0_feature_extract_model_mixed_precision/variables/variables.index  \n",
            "  inflating: downloaded_gs_model/07_efficientnetb0_feature_extract_model_mixed_precision/saved_model.pb  \n",
            "   creating: downloaded_gs_model/07_efficientnetb0_feature_extract_model_mixed_precision/assets/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_gs_model = tf.keras.models.load_model(\"downloaded_gs_model/07_efficientnetb0_feature_extract_model_mixed_precision\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFFjb65CQFFG",
        "outputId": "853b0f87-d7d6-4ec3-c814-2cd417a412c5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_158253) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_191539) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_196076) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_195780) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_196153) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_180010) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_191136) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_160354) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_195703) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_159392) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_191213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_193678) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_194051) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_158768) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_191907) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_162720) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_194708) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_196195) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_194258) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_efficientnetb0_layer_call_and_return_conditional_losses_188022) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_161995) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_efficientnetb0_layer_call_and_return_conditional_losses_183149) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_158824) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_159787) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_158482) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_158588) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_195449) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_194377) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_162615) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_192238) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_160121) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_192860) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_191865) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_160016) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_194750) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_efficientnetb0_layer_call_and_return_conditional_losses_169029) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_efficientnetb0_layer_call_and_return_conditional_losses_170771) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_159448) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_194631) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_192979) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_193263) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_160977) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_162953) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_159836) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_191581) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_158539) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_162382) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_196449) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_163238) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_162277) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_192487) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_191255) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_163009) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_194335) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_193559) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_159730) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_161759) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_192161) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_193305) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_160748) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_161371) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_192937) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_196568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_191788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_159106) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_159497) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_161315) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_efficientnetb0_layer_call_and_return_conditional_losses_184891) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_178256) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_161710) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_161653) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_159212) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_158197) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_efficientnetb0_layer_call_and_return_conditional_losses_189764) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_192606) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_195081) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_162333) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_160797) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_194009) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_195822) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_161033) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_195330) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_159163) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_160459) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_195407) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_163058) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_192280) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_162671) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference__wrapped_model_152628) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_162044) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_158873) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_160410) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_195004) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_192564) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_161082) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_161420) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_193636) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_196775) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_160072) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_161939) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_193932) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_193186) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_158302) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_195123) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_191462) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_196526) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_160692) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_loaded_gs_model = loaded_gs_model.evaluate(test_data)\n",
        "results_loaded_gs_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMCIP2JFQIs_",
        "outputId": "486efb36-9f09-4452-b1d6-6beef13614f5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "790/790 [==============================] - 74s 90ms/step - loss: 1.0881 - accuracy: 0.7066\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0880988836288452, 0.7066138386726379]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in loaded_gs_model.layers:\n",
        "  loaded_gs_model.trainable = True\n",
        "  print(layer.dtype , layer.dtype_policy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrnuNWSYTkXT",
        "outputId": "4a05a20a-f965-4ef4-d1f8-46b7c1e95490"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "float32 <Policy \"float32\">\n",
            "float32 <Policy \"mixed_float16\">\n",
            "float32 <Policy \"mixed_float16\">\n",
            "float32 <Policy \"mixed_float16\">\n",
            "float32 <Policy \"float32\">\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in loaded_gs_model.layers[1].layers[:20]:\n",
        "  print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnpqnR7qUIYR",
        "outputId": "7e801424-2ade-49a2-caa9-2bed06c78bac"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_1 True float32 <Policy \"float32\">\n",
            "rescaling True float32 <Policy \"mixed_float16\">\n",
            "normalization True float32 <Policy \"float32\">\n",
            "stem_conv_pad True float32 <Policy \"mixed_float16\">\n",
            "stem_conv True float32 <Policy \"mixed_float16\">\n",
            "stem_bn True float32 <Policy \"mixed_float16\">\n",
            "stem_activation True float32 <Policy \"mixed_float16\">\n",
            "block1a_dwconv True float32 <Policy \"mixed_float16\">\n",
            "block1a_bn True float32 <Policy \"mixed_float16\">\n",
            "block1a_activation True float32 <Policy \"mixed_float16\">\n",
            "block1a_se_squeeze True float32 <Policy \"mixed_float16\">\n",
            "block1a_se_reshape True float32 <Policy \"mixed_float16\">\n",
            "block1a_se_reduce True float32 <Policy \"mixed_float16\">\n",
            "block1a_se_expand True float32 <Policy \"mixed_float16\">\n",
            "block1a_se_excite True float32 <Policy \"mixed_float16\">\n",
            "block1a_project_conv True float32 <Policy \"mixed_float16\">\n",
            "block1a_project_bn True float32 <Policy \"mixed_float16\">\n",
            "block2a_expand_conv True float32 <Policy \"mixed_float16\">\n",
            "block2a_expand_bn True float32 <Policy \"mixed_float16\">\n",
            "block2a_expand_activation True float32 <Policy \"mixed_float16\">\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\n",
        "                                                 factor=0.2, # multiply the learning rate by 0.2 (reduce by 5x)\n",
        "                                                 patience=2,\n",
        "                                                 verbose=1, # print out when learning rate goes down\n",
        "                                                 min_lr=1e-7)"
      ],
      "metadata": {
        "id": "bxjR4c90VmKB"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_gs_model.compile(loss=\"sparse_categorical_crossentropy\", # sparse_categorical_crossentropy for labels that are *not* one-hot\n",
        "                        optimizer=tf.keras.optimizers.Adam(0.0001), # 10x lower learning rate than the default\n",
        "                        metrics=[\"accuracy\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "777TgdTXVG-8"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_101_food_classes_all_data_fine_tune = loaded_gs_model.fit(train_data,\n",
        "                                                        epochs=100, # fine-tune for a maximum of 100 epochs\n",
        "                                                        steps_per_epoch=len(train_data),\n",
        "                                                        validation_data=test_data,\n",
        "                                                        validation_steps=int(0.15 * len(test_data)), # validation during training on 15% of test data\n",
        "                                                        callbacks=[\n",
        "                                                                   model_checkpoint, # save only the best model during training\n",
        "                                                                   early_stopping, # stop model after X epochs of no improvements\n",
        "                                                                   reduce_lr]) # reduce the learning rate after X epochs of no improvements"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6SBcae1VsC8",
        "outputId": "f8408b02-ec2f-404d-9607-b270241d53cb"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2368/2368 [==============================] - 446s 165ms/step - loss: 0.9214 - accuracy: 0.7521 - val_loss: 0.7923 - val_accuracy: 0.7778 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "2368/2368 [==============================] - 374s 157ms/step - loss: 0.5778 - accuracy: 0.8394 - val_loss: 0.7611 - val_accuracy: 0.7910 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "2368/2368 [==============================] - 368s 155ms/step - loss: 0.3306 - accuracy: 0.9066 - val_loss: 0.8565 - val_accuracy: 0.7810 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "2368/2368 [==============================] - ETA: 0s - loss: 0.1733 - accuracy: 0.9482\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
            "2368/2368 [==============================] - 371s 155ms/step - loss: 0.1733 - accuracy: 0.9482 - val_loss: 0.9959 - val_accuracy: 0.7778 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "2368/2368 [==============================] - ETA: 0s - loss: 0.0354 - accuracy: 0.9919Restoring model weights from the end of the best epoch: 2.\n",
            "2368/2368 [==============================] - 372s 156ms/step - loss: 0.0354 - accuracy: 0.9919 - val_loss: 1.0771 - val_accuracy: 0.8008 - lr: 2.0000e-05\n",
            "Epoch 5: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers:\n",
        "  model.trainable = True\n",
        "  print(layer.dtype , layer.dtype_policy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Nxf7ecUWDqr",
        "outputId": "bb6dfe50-a423-4b90-95da-4b5ae054a258"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "float32 <Policy \"float32\">\n",
            "float32 <Policy \"mixed_float16\">\n",
            "float32 <Policy \"mixed_float16\">\n",
            "float32 <Policy \"mixed_float16\">\n",
            "float32 <Policy \"float32\">\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers[1].layers[:20]:\n",
        "  print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)"
      ],
      "metadata": {
        "id": "vswA54RyWLma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\", # sparse_categorical_crossentropy for labels that are *not* one-hot\n",
        "                        optimizer=tf.keras.optimizers.Adam(0.0001), # 10x lower learning rate than the default\n",
        "                        metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "69A2X7BQWVw_"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_data)"
      ],
      "metadata": {
        "id": "m0IkNR53najw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_gs_model.save(\"07_efficientnetb0_fine_tuned_101_classes_mixed_precision\")"
      ],
      "metadata": {
        "id": "9DZBSHKxd7iN"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/07_efficientnetb0_fine_tuned_101_classes_mixed_precision.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7SkQX1zeXcT",
        "outputId": "4b1f437a-4814-480b-b287-4e6606586f32"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-27 16:14:04--  https://storage.googleapis.com/ztm_tf_course/food_vision/07_efficientnetb0_fine_tuned_101_classes_mixed_precision.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.128.207, 74.125.143.207, 173.194.69.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.128.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 46790356 (45M) [application/zip]\n",
            "Saving to: ‘07_efficientnetb0_fine_tuned_101_classes_mixed_precision.zip’\n",
            "\n",
            "07_efficientnetb0_f 100%[===================>]  44.62M  23.2MB/s    in 1.9s    \n",
            "\n",
            "2024-06-27 16:14:06 (23.2 MB/s) - ‘07_efficientnetb0_fine_tuned_101_classes_mixed_precision.zip’ saved [46790356/46790356]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir downloaded_fine_tuned_gs_model # create separate directory for fine-tuned model downloaded from Google Storage\n",
        "!unzip 07_efficientnetb0_fine_tuned_101_classes_mixed_precision -d downloaded_fine_tuned_gs_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kzsi4X7eVAN",
        "outputId": "d25f4e71-9605-4005-8a46-ef9f1e193177"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  07_efficientnetb0_fine_tuned_101_classes_mixed_precision.zip\n",
            "   creating: downloaded_fine_tuned_gs_model/07_efficientnetb0_fine_tuned_101_classes_mixed_precision/\n",
            "   creating: downloaded_fine_tuned_gs_model/07_efficientnetb0_fine_tuned_101_classes_mixed_precision/variables/\n",
            "  inflating: downloaded_fine_tuned_gs_model/07_efficientnetb0_fine_tuned_101_classes_mixed_precision/variables/variables.data-00000-of-00001  \n",
            "  inflating: downloaded_fine_tuned_gs_model/07_efficientnetb0_fine_tuned_101_classes_mixed_precision/variables/variables.index  \n",
            "  inflating: downloaded_fine_tuned_gs_model/07_efficientnetb0_fine_tuned_101_classes_mixed_precision/saved_model.pb  \n",
            "   creating: downloaded_fine_tuned_gs_model/07_efficientnetb0_fine_tuned_101_classes_mixed_precision/assets/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_fine_tuned_gs_model = tf.keras.models.load_model(\"downloaded_fine_tuned_gs_model/07_efficientnetb0_fine_tuned_101_classes_mixed_precision\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lF5OD9eteeoM",
        "outputId": "3bd2657f-b0f2-4760-de83-fc76949d0a5d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_443625) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_412189) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_409120) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_446895) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_442329) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_efficientnetb0_layer_call_and_return_conditional_losses_421687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_411851) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_446637) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_447353) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_445426) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_442371) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_efficientnetb0_layer_call_and_return_conditional_losses_419945) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_442703) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_445173) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_efficientnetb0_layer_call_and_return_conditional_losses_440876) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_447774) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_413771) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_413200) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_410834) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_411277) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_410210) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_445215) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_446974) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_443414) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_413433) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_442250) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_410890) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_413876) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_414056) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_409981) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_efficientnetb0_layer_call_and_return_conditional_losses_435905) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_410266) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_409924) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_410939) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_444794) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_412862) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_445926) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference__wrapped_model_403250) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_445547) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_447274) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_412471) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_412238) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_411510) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_445884) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_411615) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_410315) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_444336) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_429172) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_409406) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_412577) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_efficientnetb0_layer_call_and_return_conditional_losses_434163) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_447985) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_412757) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_446184) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_411566) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_444415) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_442914) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_409300) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_443372) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_447395) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_445094) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_413489) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_410548) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_412813) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_444083) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_444836) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_447732) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_411795) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_446516) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_444125) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_444715) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_443035) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_442661) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_430926) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_444004) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_413095) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_411900) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_447016) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_412528) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_443746) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_442993) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_443293) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_446305) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_446595) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_413827) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_443704) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_409357) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_413151) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_410030) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_444457) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_409071) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_445805) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_411228) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_442582) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_410654) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_447653) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_446263) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_413538) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_412133) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_409691) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_409586) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_445505) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_410605) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_409015) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_409642) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_411172) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_efficientnetb0_layer_call_and_return_conditional_losses_439134) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make preds on a series of random images\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import random\n",
        "\n",
        "plt.figure(figsize=(17, 10))\n",
        "filepath = \"/content/cheesecake.jpeg\"\n",
        "  # Load the image and make predictions\n",
        "class_name = \"cheesecake\"\n",
        "img = load_and_prep_image(filepath, scale=False) # don't scale images for EfficientNet predictions\n",
        "pred_prob = model.predict(tf.expand_dims(img, axis=0)) # model accepts tensors of shape [None, 224, 224, 3]\n",
        "pred_class = class_names[pred_prob.argmax()] # find the predicted class\n",
        "\n",
        "# Plot the image(s)\n",
        "plt.imshow(img/255.)\n",
        "if class_name == pred_class: # Change the color of text based on whether prediction is right or wrong\n",
        "  title_color = \"g\"\n",
        "else:\n",
        "  title_color = \"r\"\n",
        "plt.title(f\"actual: {class_name}, pred: {pred_class}, prob: {pred_prob.max():.2f}\", c=title_color)\n",
        "plt.axis(False);"
      ],
      "metadata": {
        "id": "P4zp1QnReng1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GO6E1eQZfLN2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}